{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QInk_g_jLaVf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could Not Find C:\\Users\\buime\\SamVanderlinda.github.io\\-r\n",
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "#!rm -r sample_data/ # For Mac Users\n",
    "!del -r \"sample_data/\" # For Window Users\n",
    "\n",
    "# Why deleting sample_data?\n",
    "# What is sample_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "RYx38RqMSD4g"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_slim in c:\\users\\buime\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in c:\\users\\buime\\anaconda3\\lib\\site-packages (from tf_slim) (0.11.0)\n",
      "Requirement already satisfied: six in c:\\users\\buime\\anaconda3\\lib\\site-packages (from absl-py>=0.2.2->tf_slim) (1.15.0)\n",
      "Collecting scann\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement scann (from versions: none)\n",
      "ERROR: No matching distribution found for scann\n"
     ]
    }
   ],
   "source": [
    "!pip install tf_slim\n",
    "!pip install scann\n",
    "\n",
    "# Why pip install scann not working? Need Linux environment? \n",
    "# \"ScaNN supports Linux environments running Python versions 3.6-3.9\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WwqDkpvmFIfL"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from typing import Mapping\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "yiE5UI8kR-kB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\buime\\SamVanderlinda.github.io\\models\\research\\audioset\\vggish\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "Updating files:  15% (404/2669)\n",
      "Updating files:  16% (428/2669)\n",
      "Updating files:  17% (454/2669)\n",
      "Updating files:  18% (481/2669)\n",
      "Updating files:  19% (508/2669)\n",
      "Updating files:  20% (534/2669)\n",
      "Updating files:  21% (561/2669)\n",
      "Updating files:  22% (588/2669)\n",
      "Updating files:  23% (614/2669)\n",
      "Updating files:  24% (641/2669)\n",
      "Updating files:  25% (668/2669)\n",
      "Updating files:  26% (694/2669)\n",
      "Updating files:  27% (721/2669)\n",
      "Updating files:  28% (748/2669)\n",
      "Updating files:  29% (775/2669)\n",
      "Updating files:  30% (801/2669)\n",
      "Updating files:  31% (828/2669)\n",
      "Updating files:  32% (855/2669)\n",
      "Updating files:  33% (881/2669)\n",
      "Updating files:  34% (908/2669)\n",
      "Updating files:  35% (935/2669)\n",
      "Updating files:  36% (961/2669)\n",
      "Updating files:  37% (988/2669)\n",
      "Updating files:  37% (999/2669)\n",
      "Updating files:  38% (1015/2669)\n",
      "Updating files:  39% (1041/2669)\n",
      "Updating files:  40% (1068/2669)\n",
      "Updating files:  41% (1095/2669)\n",
      "Updating files:  42% (1121/2669)\n",
      "Updating files:  43% (1148/2669)\n",
      "Updating files:  44% (1175/2669)\n",
      "Updating files:  45% (1202/2669)\n",
      "Updating files:  46% (1228/2669)\n",
      "Updating files:  47% (1255/2669)\n",
      "Updating files:  48% (1282/2669)\n",
      "Updating files:  49% (1308/2669)\n",
      "Updating files:  50% (1335/2669)\n",
      "Updating files:  51% (1362/2669)\n",
      "Updating files:  52% (1388/2669)\n",
      "Updating files:  52% (1395/2669)\n",
      "Updating files:  53% (1415/2669)\n",
      "Updating files:  54% (1442/2669)\n",
      "Updating files:  55% (1468/2669)\n",
      "Updating files:  56% (1495/2669)\n",
      "Updating files:  57% (1522/2669)\n",
      "Updating files:  58% (1549/2669)\n",
      "Updating files:  59% (1575/2669)\n",
      "Updating files:  60% (1602/2669)\n",
      "Updating files:  61% (1629/2669)\n",
      "Updating files:  62% (1655/2669)\n",
      "Updating files:  63% (1682/2669)\n",
      "Updating files:  64% (1709/2669)\n",
      "Updating files:  65% (1735/2669)\n",
      "Updating files:  66% (1762/2669)\n",
      "Updating files:  67% (1789/2669)\n",
      "Updating files:  68% (1815/2669)\n",
      "Updating files:  68% (1822/2669)\n",
      "Updating files:  69% (1842/2669)\n",
      "Updating files:  70% (1869/2669)\n",
      "Updating files:  71% (1895/2669)\n",
      "Updating files:  72% (1922/2669)\n",
      "Updating files:  73% (1949/2669)\n",
      "Updating files:  74% (1976/2669)\n",
      "Updating files:  75% (2002/2669)\n",
      "Updating files:  76% (2029/2669)\n",
      "Updating files:  77% (2056/2669)\n",
      "Updating files:  78% (2082/2669)\n",
      "Updating files:  79% (2109/2669)\n",
      "Updating files:  80% (2136/2669)\n",
      "Updating files:  81% (2162/2669)\n",
      "Updating files:  82% (2189/2669)\n",
      "Updating files:  83% (2216/2669)\n",
      "Updating files:  84% (2242/2669)\n",
      "Updating files:  85% (2269/2669)\n",
      "Updating files:  86% (2296/2669)\n",
      "Updating files:  87% (2323/2669)\n",
      "Updating files:  88% (2349/2669)\n",
      "Updating files:  89% (2376/2669)\n",
      "Updating files:  90% (2403/2669)\n",
      "Updating files:  91% (2429/2669)\n",
      "Updating files:  92% (2456/2669)\n",
      "Updating files:  93% (2483/2669)\n",
      "Updating files:  94% (2509/2669)\n",
      "Updating files:  95% (2536/2669)\n",
      "Updating files:  96% (2563/2669)\n",
      "Updating files:  96% (2584/2669)\n",
      "Updating files:  97% (2589/2669)\n",
      "Updating files:  98% (2616/2669)\n",
      "Updating files:  99% (2643/2669)\n",
      "Updating files: 100% (2669/2669)\n",
      "Updating files: 100% (2669/2669), done.\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  1  277M    1 4446k    0     0  3800k      0  0:01:14  0:00:01  0:01:13 3804k\n",
      "  5  277M    5 16.1M    0     0  7745k      0  0:00:36  0:00:02  0:00:34 7748k\n",
      " 11  277M   11 30.7M    0     0   9.8M      0  0:00:28  0:00:03  0:00:25  9.8M\n",
      " 17  277M   17 48.3M    0     0  11.6M      0  0:00:23  0:00:04  0:00:19 11.6M\n",
      " 21  277M   21 59.3M    0     0  6419k      0  0:00:44  0:00:09  0:00:35 6630k\n",
      " 26  277M   26 73.0M    0     0  7378k      0  0:00:38  0:00:10  0:00:28 7843k\n",
      " 30  277M   30 84.4M    0     0  7762k      0  0:00:36  0:00:11  0:00:25 7765k\n",
      " 34  277M   34 95.3M    0     0  8041k      0  0:00:35  0:00:12  0:00:23 7345k\n",
      " 38  277M   38  107M    0     0  8350k      0  0:00:34  0:00:13  0:00:21 6695k\n",
      " 43  277M   43  122M    0     0  8844k      0  0:00:32  0:00:14  0:00:18 13.4M\n",
      " 47  277M   47  132M    0     0  8989k      0  0:00:31  0:00:15  0:00:16 11.9M\n",
      " 51  277M   51  143M    0     0  9106k      0  0:00:31  0:00:16  0:00:15 11.8M\n",
      " 56  277M   56  155M    0     0  9304k      0  0:00:30  0:00:17  0:00:13 12.0M\n",
      " 62  277M   62  173M    0     0  9772k      0  0:00:29  0:00:18  0:00:11 13.2M\n",
      " 66  277M   66  183M    0     0  9843k      0  0:00:28  0:00:19  0:00:09 12.3M\n",
      " 71  277M   71  198M    0     0   9.8M      0  0:00:28  0:00:20  0:00:08 13.0M\n",
      " 75  277M   75  209M    0     0   9.9M      0  0:00:27  0:00:21  0:00:06 13.2M\n",
      " 79  277M   79  221M    0     0  10.0M      0  0:00:27  0:00:22  0:00:05 13.1M\n",
      " 86  277M   86  239M    0     0  10.3M      0  0:00:26  0:00:23  0:00:03 13.3M\n",
      " 87  277M   87  242M    0     0  10.0M      0  0:00:27  0:00:24  0:00:03 11.7M\n",
      " 88  277M   88  246M    0     0   9.8M      0  0:00:28  0:00:25  0:00:03 9857k\n",
      " 90  277M   90  251M    0     0  9691k      0  0:00:29  0:00:26  0:00:03 7890k\n",
      " 92  277M   92  255M    0     0  9655k      0  0:00:29  0:00:27  0:00:02 7007k\n",
      " 93  277M   93  259M    0     0  9452k      0  0:00:30  0:00:28  0:00:02 4085k\n",
      " 95  277M   95  266M    0     0  9308k      0  0:00:30  0:00:29  0:00:01 4659k\n",
      " 97  277M   97  269M    0     0  9152k      0  0:00:31  0:00:30  0:00:01 4707k\n",
      " 99  277M   99  275M    0     0  9051k      0  0:00:31  0:00:31 --:--:-- 5306k\n",
      "100  277M  100  277M    0     0  9045k      0  0:00:31  0:00:31 --:--:-- 5186k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 73020  100 73020    0     0   181k      0 --:--:-- --:--:-- --:--:--  182k\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tensorflow/models.git\n",
    "%cd models/research/audioset/vggish\n",
    "!curl -O https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
    "!curl -O https://storage.googleapis.com/audioset/vggish_pca_params.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "brxugRDvBuc3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "tar: Error opening archive: Failed to open 'features.tar.gz'\n"
     ]
    }
   ],
   "source": [
    "# Get labels and indexes of youtube noises\n",
    "!wget http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/balanced_train_segments.csv\n",
    "!wget http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/class_labels_indices.csv\n",
    "!wget storage.googleapis.com/us_audioset/youtube_corpus/v1/features/features.tar.gz\n",
    "\n",
    "# Extract dataset\n",
    "!tar -xf features.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qF2Gjzn4FOK7"
   },
   "outputs": [],
   "source": [
    "def load_labels_map() -> Mapping[int, str]:\n",
    "  # Build index to label map\n",
    "  index_label_map = dict()\n",
    "\n",
    "  class_labels_file = \"class_labels_indices.csv\"\n",
    "  with open(class_labels_file) as csv_file:\n",
    "    csvreader = csv.reader(csv_file)\n",
    "\n",
    "    # Skip header\n",
    "    fields = next(csvreader)\n",
    "\n",
    "    # extracting each data row one by one\n",
    "    for row in csvreader:\n",
    "      mid_label_map.update({int(row[0]) : row[2]})   # For example {\"8\" : \"Shout\"}\n",
    "\n",
    "  return mid_label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FSiQeKNWa0Td"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ls' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ls /content/audioset_v1_embeddings/bal_train/a1.tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UPLUSOe6WyQs"
   },
   "outputs": [],
   "source": [
    "# Load audio tfrecords\n",
    "#!ls /content/audioset_v1_embeddings/bal_train/\n",
    "for example_str in tf.python_io.tf_record_iterator(\"/content/audioset_v1_embeddings/bal_train/00.tfrecord\"):\n",
    "    seq_example = tf.train.SequenceExample.FromString(example_str)\n",
    "    print(seq_example.context.feature['video_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FyJ_StxgczfI",
    "outputId": "f169ec18-193b-47d8-faa8-1dcdc3088f53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMALLEST MIN_SEC_FOUND:  1\n"
     ]
    }
   ],
   "source": [
    "# Takes approximately 45 - 50 seconds to run\n",
    "# Load audio tfrecords\n",
    "#!ls /content/audioset_v1_embeddings/bal_train/\n",
    "files = os.listdir('/content/audioset_v1_embeddings/bal_train/')\n",
    "video_audio_map = dict()\n",
    "min_sec_found = 10 # doesnt matter\n",
    "\n",
    "for filename in files:\n",
    "  if not filename.endswith(\".tfrecord\"):\n",
    "    continue\n",
    "\n",
    "  for example_str in tf.compat.v1.io.tf_record_iterator(os.path.join(\"/content/audioset_v1_embeddings/bal_train/\", filename)):\n",
    "    seq_example = tf.train.SequenceExample.FromString(example_str)\n",
    "    min_sec_found = min(min_sec_found, len(seq_example.feature_lists.feature_list['audio_embedding'].feature))\n",
    "    if len(seq_example.feature_lists.feature_list['audio_embedding'].feature) >= 5:\n",
    "      bytes_2d_list = seq_example.feature_lists.feature_list['audio_embedding'].feature[0:5]\n",
    "      flattened_byte_list = []\n",
    "      for bytes_list in bytes_2d_list:\n",
    "        flattened_byte_list.extend(np.frombuffer(bytes_list.bytes_list.value[0], dtype=np.uint8))\n",
    "      video_audio_map.update({str(seq_example.context.feature['video_id'].bytes_list.value[0], 'utf-8'): flattened_byte_list})\n",
    "print(\"SMALLEST MIN_SEC_FOUND: \", min_sec_found)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "id": "0kH6RoIjoCeX"
   },
   "outputs": [],
   "source": [
    "dataset = np.empty((0, 640), np.uint8)\n",
    "index_video_map = dict()\n",
    "for idx, feature_list_key in enumerate(video_audio_map.keys()):\n",
    "  index_video_map.update({idx : feature_list_key})\n",
    "  feature_list = video_audio_map[feature_list_key]\n",
    "  dataset = np.append(dataset, np.array([feature_list]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "WiYQ-2tvWz5k"
   },
   "outputs": [],
   "source": [
    "# Take approximately 42 seconds\n",
    "# Build ScaNN index\n",
    "import scann\n",
    "dataset = np.array(list(video_audio_map.values()))\n",
    "num_results = 10 \n",
    "searcher = scann.scann_ops_pybind.builder(dataset, num_results, \"dot_product\").tree(\n",
    "    num_leaves=2000, num_leaves_to_search=100, training_sample_size=250000).score_ah(\n",
    "    2, anisotropic_quantization_threshold=0.2).reorder(100).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "id": "dYyHcbwEsUDH"
   },
   "outputs": [],
   "source": [
    "queries = np.array(np.ones_like(640, shape=(1, 640)))\n",
    "neighbors, distances = searcher.search_batched(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2p6DxIKQs36y",
    "outputId": "0cf84c50-982f-4092-b02f-9c1e016197f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://youtube.com/watch?v=ArsKCV3rkc4\n",
      "http://youtube.com/watch?v=4HSkwF586ro\n",
      "http://youtube.com/watch?v=QM4qxOYDwHo\n",
      "http://youtube.com/watch?v=ZaeARmx4m0k\n",
      "http://youtube.com/watch?v=DRGpwij9No8\n",
      "http://youtube.com/watch?v=UGtYWC-ddF4\n",
      "http://youtube.com/watch?v=zFRreJxXDFw\n",
      "http://youtube.com/watch?v=Dj6vz-bsHXY\n",
      "http://youtube.com/watch?v=smTo8842-5c\n",
      "http://youtube.com/watch?v=FOxIDRWTHZc\n"
     ]
    }
   ],
   "source": [
    "for neighbor in neighbors[0]:\n",
    "  video_id = index_video_map[neighbor]\n",
    "\n",
    "  print(f\"http://youtube.com/watch?v={video_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lb5lG6yRT_N4"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "\n",
    "import vggish_input\n",
    "import vggish_params\n",
    "import vggish_postprocess\n",
    "import vggish_slim\n",
    "\n",
    "# Paths to downloaded VGGish files.\n",
    "checkpoint_path = 'vggish_model.ckpt'\n",
    "pca_params_path = 'vggish_pca_params.npz'\n",
    "\n",
    "# Relative tolerance of errors in mean and standard deviation of embeddings.\n",
    "rel_error = 0.1  # Up to 10%\n",
    "\n",
    "# Generate a 1 kHz sine wave at 44.1 kHz (we use a high sampling rate\n",
    "# to test resampling to 16 kHz during feature extraction).\n",
    "########## REPLACE WITH CODE TO LOAD WAVEFORM FROM USER\n",
    "num_secs = 4\n",
    "freq = 1000\n",
    "sr = 44100\n",
    "t = np.arange(0, num_secs, 1 / sr)\n",
    "x = np.sin(2 * np.pi * freq * t)\n",
    "\n",
    "# Produce a batch of log mel spectrogram examples.\n",
    "input_batch = vggish_input.waveform_to_examples(x, sr)\n",
    "np.testing.assert_equal(\n",
    "    input_batch.shape,\n",
    "    [num_secs, vggish_params.NUM_FRAMES, vggish_params.NUM_BANDS])\n",
    "\n",
    "# Define VGGish, load the checkpoint, and run the batch through the model to\n",
    "# produce embeddings.\n",
    "with tf.Graph().as_default(), tf.Session() as sess:\n",
    "  vggish_slim.define_vggish_slim()\n",
    "  vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint_path)\n",
    "\n",
    "  features_tensor = sess.graph.get_tensor_by_name(\n",
    "      vggish_params.INPUT_TENSOR_NAME)\n",
    "  embedding_tensor = sess.graph.get_tensor_by_name(\n",
    "      vggish_params.OUTPUT_TENSOR_NAME)\n",
    "  [embedding_batch] = sess.run([embedding_tensor],\n",
    "                               feed_dict={features_tensor: input_batch})\n",
    "  print('Num of embeddings: ', len(embedding_batch))\n",
    "  print('VGGish embedding: ', embedding_batch[0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Audio Deep Retrieval.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
