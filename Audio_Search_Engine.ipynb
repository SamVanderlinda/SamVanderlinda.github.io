{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio Search Engine.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bLiqdfuEQnT"
      },
      "source": [
        "# Audio Search Engine\n",
        "Developed during Pinnacle 2021 Olympic Hackathon competition.\n",
        "\n",
        "This notebook is the backend for the INSERT_PROJECT_NAME.\n",
        "\n",
        "Authors: Megan Bui, Sam Vanderlinda, Abduselam Shaltu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yup4eNtgE5LL"
      },
      "source": [
        "## Setup\n",
        "Installs required libraries, loads imports, downloads dataset/models, and defines required functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYx38RqMSD4g"
      },
      "source": [
        "!pip install tf_slim\n",
        "!pip install scann\n",
        "!pip install flask_ngrok\n",
        "!pip install flask_cors\n",
        "!pip install pydub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brxugRDvBuc3"
      },
      "source": [
        "# Get labels and indexes of youtube noises.\n",
        "!wget http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/balanced_train_segments.csv\n",
        "!wget http://storage.googleapis.com/us_audioset/youtube_corpus/v1/csv/class_labels_indices.csv\n",
        "!wget storage.googleapis.com/us_audioset/youtube_corpus/v1/features/features.tar.gz\n",
        "\n",
        "# Extract dataset.\n",
        "!tar -xf features.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sy1M5_IhQ2CX"
      },
      "source": [
        "# Clone audio encoder model from Google Storage.\n",
        "!git clone https://github.com/tensorflow/models.git\n",
        "%cd models/research/audioset/vggish\n",
        "!curl -O https://storage.googleapis.com/audioset/vggish_model.ckpt\n",
        "!curl -O https://storage.googleapis.com/audioset/vggish_pca_params.npz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwqDkpvmFIfL"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import csv\n",
        "import scann\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from typing import Mapping\n",
        "from itertools import chain\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from __future__ import print_function\n",
        "from pydub import AudioSegment\n",
        "\n",
        "# Flask server related imports.\n",
        "from flask import Flask, json, request, stream_with_context, jsonify\n",
        "from flask_cors import CORS, cross_origin\n",
        "\n",
        "# Audio encoder imports.\n",
        "import vggish_input\n",
        "import vggish_params\n",
        "import vggish_postprocess\n",
        "import vggish_slim"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF2Gjzn4FOK7"
      },
      "source": [
        "# Build dict with video id mapped to audio features.\n",
        "# Takes approximately 45 - 50 seconds to run.\n",
        "def load_video_audio_map():\n",
        "  files = os.listdir('/content/audioset_v1_embeddings/bal_train/')\n",
        "  video_audio_map = dict()\n",
        "\n",
        "  for filename in files:\n",
        "    # Ignore non-tfrecord files.\n",
        "    if not filename.endswith(\".tfrecord\"):\n",
        "      continue\n",
        "\n",
        "    for example_str in tf.compat.v1.io.tf_record_iterator(os.path.join(\"/content/audioset_v1_embeddings/bal_train/\", filename)):\n",
        "      seq_example = tf.train.SequenceExample.FromString(example_str)\n",
        "      if len(seq_example.feature_lists.feature_list['audio_embedding'].feature) >= 5:\n",
        "        bytes_2d_list = seq_example.feature_lists.feature_list['audio_embedding'].feature[0:5]\n",
        "        flattened_byte_list = []\n",
        "        for bytes_list in bytes_2d_list:\n",
        "          flattened_byte_list.extend(np.frombuffer(bytes_list.bytes_list.value[0], dtype=np.uint8))\n",
        "        video_audio_map.update({str(seq_example.context.feature['video_id'].bytes_list.value[0], 'utf-8'): flattened_byte_list})\n",
        "\n",
        "  return video_audio_map\n",
        "\n",
        "# Build dict with video id mapped to start time.\n",
        "def load_video_start_map() -> Mapping[str, int]:\n",
        "  video_start_map = dict()\n",
        "\n",
        "  segments_file = \"/content/balanced_train_segments.csv\"\n",
        "  with open(segments_file) as csv_file:\n",
        "    csvreader = csv.reader(csv_file)\n",
        "\n",
        "    # Skip first and second row which are just stats.\n",
        "    next(csvreader) \n",
        "    next(csvreader)\n",
        "\n",
        "    # Skip header.\n",
        "    fields = next(csvreader)\n",
        "\n",
        "    # Extract each video data row by row.\n",
        "    for row in csvreader:\n",
        "      video_start_map.update({row[0] : int(float(row[1]))})  # {\"QM4qxOYDwHo\" : 430}\n",
        "\n",
        "  return video_start_map\n",
        "\n",
        "# Build dict mapping index to video id.\n",
        "def load_index_video_map(video_audio_map):\n",
        "  index_video_map = dict()\n",
        "  for idx, feature_list_key in enumerate(video_audio_map.keys()):\n",
        "    index_video_map.update({idx : feature_list_key})\n",
        "  \n",
        "  return index_video_map\n",
        "\n",
        "# Build a ScaNN index for later ANN lookups. Takes approximately 42 seconds.\n",
        "def load_search_engine(video_audio_map, num_results):\n",
        "  dataset = np.array(list(video_audio_map.values()))\n",
        "  search_engine = scann.scann_ops_pybind.builder(dataset, num_results, \"dot_product\").tree(\n",
        "      num_leaves=2000, num_leaves_to_search=100, training_sample_size=250000).score_ah(\n",
        "      2, anisotropic_quantization_threshold=0.2).reorder(100).build()\n",
        "  return search_engine\n",
        "\n",
        "# Convert mp3 file to wav and ensure the saved wav file is 5 seconds long.\n",
        "def convert_mp3_to_wav(mp3_file_path):\n",
        "  base_file_path = mp3_file_path[0 : mp3_file_path.index(\".mp3\")]\n",
        "  wav_file_path = f\"{base_file_path}.wav\"\n",
        "  sound = AudioSegment.from_mp3(mp3_file_path)\n",
        "\n",
        "  # pydub does things in milliseconds.\n",
        "  five_seconds = 5 * 1000       \n",
        "\n",
        "  # Add silence if duration not long enough.\n",
        "  if sound.duration_seconds < 5:\n",
        "    sound += AudioSegment.silent(duration=five_seconds)\n",
        "\n",
        "  sound = sound[0 : five_seconds]   # First 5 seconds.\n",
        "  sound.export(wav_file_path, 'wav')\n",
        "\n",
        "  return wav_file_path"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb5lG6yRT_N4"
      },
      "source": [
        "# Encode an audio file in wav format.\n",
        "# Returns an embedding in the form  \n",
        "def encode_audio(wav_file, sr=None):\n",
        "  # Paths to downloaded VGGish files.\n",
        "  checkpoint_path = 'vggish_model.ckpt'\n",
        "  pca_params_path = 'vggish_pca_params.npz'\n",
        "\n",
        "  # Relative tolerance of errors in mean and standard deviation of embeddings.\n",
        "  rel_error = 0.1  # Up to 10%\n",
        "\n",
        "  # Produce a batch of log mel spectrogram examples.\n",
        "  if sr:\n",
        "    input_batch = vggish_input.waveform_to_examples(wav_file, sr)\n",
        "  else:\n",
        "    input_batch = vggish_input.wavfile_to_examples(wav_file)\n",
        "\n",
        "  # Define VGGish, load the checkpoint, and run the batch through the model to\n",
        "  # produce embeddings.\n",
        "  with tf.compat.v1.Graph().as_default(), tf.compat.v1.Session() as sess:\n",
        "    vggish_slim.define_vggish_slim()\n",
        "    vggish_slim.load_vggish_slim_checkpoint(sess, checkpoint_path)\n",
        "\n",
        "    features_tensor = sess.graph.get_tensor_by_name(\n",
        "        vggish_params.INPUT_TENSOR_NAME)\n",
        "    embedding_tensor = sess.graph.get_tensor_by_name(\n",
        "        vggish_params.OUTPUT_TENSOR_NAME)\n",
        "    [embedding_batch] = sess.run([embedding_tensor],\n",
        "                                feed_dict={features_tensor: input_batch})\n",
        "    \n",
        "  pproc = vggish_postprocess.Postprocessor(pca_params_path)\n",
        "  postprocessed_batch = pproc.postprocess(embedding_batch)\n",
        "\n",
        "  embedding = []\n",
        "  for postprocessed_embedding in postprocessed_batch:\n",
        "    embedding.extend(postprocessed_embedding)\n",
        "\n",
        "  return np.array(embedding, ndmin=2), postprocessed_batch,"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6N3K1d-HqyLD"
      },
      "source": [
        "## Flask Server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMHGx5bV3_rN"
      },
      "source": [
        "# Load all server required variables needed for recommendation.\n",
        "num_results = 10\n",
        "mp3_file_path = '/content/recording.mp3'\n",
        "\n",
        "video_audio_map = load_video_audio_map()\n",
        "video_start_map = load_video_start_map()\n",
        "index_video_map = load_index_video_map(video_audio_map)\n",
        "\n",
        "search_engine = load_search_engine(video_audio_map, num_results)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmdOr39eqXcp",
        "outputId": "ff659c13-66c2-4cd6-a60c-13a2ab13e305"
      },
      "source": [
        "# Server details.\n",
        "api = Flask(__name__)\n",
        "cors = CORS(api)\n",
        "api.config['CORS_HEADERS'] = 'Content-Type'\n",
        "run_with_ngrok(api)   \n",
        "\n",
        "# Endpoint needed for recommendation for audio snippets.\n",
        "@api.route('/recommend', methods=['GET', 'POST'])\n",
        "@cross_origin(origin='*',headers=['Content-Type'])\n",
        "def recommend():\n",
        "  files = request.files\n",
        "  files['rawAudioData'].save(mp3_file_path)\n",
        "  wav_file_path = convert_mp3_to_wav(mp3_file_path)\n",
        "\n",
        "  # Encode audio into embedding with shape (1, 640).\n",
        "  flat_audio_embedding, batched_embeddings = encode_audio(wav_file_path)\n",
        "\n",
        "  # Perform approximate nearest neighbor(ANN) search. \n",
        "  neighbors, distances = search_engine.search_batched(flat_audio_embedding)\n",
        "\n",
        "  # Extract video ids and start time from approximate nearest neighbor search.\n",
        "  videos = []\n",
        "  for neighbor in neighbors[0]:\n",
        "    video_id = index_video_map[neighbor]\n",
        "    start_time_seconds = video_start_map[video_id]\n",
        "    videos.append([video_id, start_time_seconds])\n",
        "\n",
        "  # Cleanup\n",
        "  os.remove(mp3_file_path)\n",
        "  os.remove(wav_file_path)\n",
        "\n",
        "  return {\"videos\" : videos}\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    api.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://ba4f-104-199-122-141.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:25:46] \"\u001b[31m\u001b[1mGET /recommend HTTP/1.1\u001b[0m\" 400 -\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:26:08] \"\u001b[37mPOST /recommend HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:27:10] \"\u001b[37mPOST /recommend HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:29:58] \"\u001b[37mPOST /recommend HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:35:35] \"\u001b[37mPOST /recommend HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:38:42] \"\u001b[37mPOST /recommend HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:39:16] \"\u001b[37mPOST /recommend HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:39:33] \"\u001b[37mPOST /recommend HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:42:59] \"\u001b[37mPOST /recommend HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:43:49] \"\u001b[37mPOST /recommend HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:44:04] \"\u001b[37mPOST /recommend HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:44:13] \"\u001b[37mPOST /recommend HTTP/1.1\u001b[0m\" 200 -\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1694: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:336: UserWarning: `tf.layers.flatten` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Flatten` instead.\n",
            "  warnings.warn('`tf.layers.flatten` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Restoring parameters from vggish_model.ckpt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127.0.0.1 - - [19/Sep/2021 04:44:25] \"\u001b[37mPOST /recommend HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    }
  ]
}